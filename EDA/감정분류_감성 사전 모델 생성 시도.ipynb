{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broad-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1bcb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, AlbertModel, BertModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import hanja\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1de3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a95287ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH + 'train_감정분류.csv', index_col=0)\n",
    "test = pd.read_csv(PATH + 'test_감정분류.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c9abd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = list(train['감정_소분류'].unique())\n",
    "\n",
    "emotion_ls = []\n",
    "for t in train['감정_소분류']:\n",
    "    emotion_ls.append(emotion.index(t))\n",
    "    \n",
    "train['감정_대분류'] = emotion_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83818b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = list(test['감정_소분류'].unique())\n",
    "\n",
    "emotion_ls = []\n",
    "for t in test['감정_소분류']:\n",
    "    emotion_ls.append(emotion.index(t))\n",
    "    \n",
    "test['감정_대분류'] = emotion_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ada95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train['응답정리']\n",
    "y_train = train['감정_대분류']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25730324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "228463    1\n",
       "228464    1\n",
       "228465    1\n",
       "228466    1\n",
       "228467    1\n",
       "Name: 감정_대분류, Length: 228468, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2157c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['응답정리']\n",
    "y_test = test['감정_대분류']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b20516",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "339e8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 81.0/81.0 [00:00<00:00, 42.3kB/s]\n",
      "Downloading: 100%|██████████| 336k/336k [00:00<00:00, 375kB/s]  \n",
      "Downloading: 100%|██████████| 684/684 [00:00<00:00, 319kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizerFast'. \n",
      "The class this function is called from is 'BertTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_bert_kor_base = BertTokenizerFast.from_pretrained(\"kykim/albert-kor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09db2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_t = x_train.to_numpy().reshape(-1,1)\n",
    "labels_t = y_train.to_numpy().reshape(-1,1)\n",
    "# oversample = RandomOverSampler()\n",
    "# X_over, y_over = oversample.fit_resample(titles_t, labels_t)\n",
    "# train = pd.DataFrame({'title':X_over.reshape(-1), 'topic_idx':y_over.reshape(-1)})\n",
    "train = pd.DataFrame({'title':titles_t.reshape(-1), 'topic_idx':labels_t.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dd7d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_t = x_test.to_numpy().reshape(-1,1)\n",
    "labels_t = y_test.to_numpy().reshape(-1,1)\n",
    "# oversample = RandomOverSampler()\n",
    "# X_over, y_over = oversample.fit_resample(titles_t, labels_t)\n",
    "# train = pd.DataFrame({'title':X_over.reshape(-1), 'topic_idx':y_over.reshape(-1)})\n",
    "test = pd.DataFrame({'title':titles_t.reshape(-1), 'topic_idx':labels_t.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e825330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 데이터 클래스 생성\n",
    "class NewsSubjectDataset(Dataset):\n",
    "  def __init__(self, subjects, targets, tokenizer, max_len):\n",
    "    self.subjects = subjects\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.subjects)\n",
    "  def __getitem__(self, item):\n",
    "    subject = str(self.subjects[item])\n",
    "    target = self.targets[item]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      subject,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return {\n",
    "      'subject_text': subject,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size, shuffle_=False, valid=False):\n",
    "  if valid:\n",
    "    ds = NewsSubjectDataset(\n",
    "      subjects=df.title.to_numpy(),\n",
    "      targets=np.zeros(len(df)),\n",
    "      tokenizer=tokenizer,\n",
    "      max_len=max_len\n",
    "      )\n",
    "  else:\n",
    "    ds = NewsSubjectDataset(\n",
    "      subjects=df.title.to_numpy(),\n",
    "      targets=df.topic_idx.to_numpy(),\n",
    "      tokenizer=tokenizer,\n",
    "      max_len=max_len\n",
    "    )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle = shuffle_\n",
    "  )\n",
    "  \n",
    "# 데이터 로더 생성\n",
    "BATCH_SIZE =64\n",
    "MAX_LEN =32\n",
    "train_data_loader = create_data_loader(train, tokenizer_bert_kor_base, MAX_LEN, BATCH_SIZE, shuffle_=True)\n",
    "valid_data_loader = create_data_loader(test, tokenizer_bert_kor_base, MAX_LEN, BATCH_SIZE, valid=True)\n",
    "import random\n",
    "class NewsSubjectClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(NewsSubjectClassifier, self).__init__()\n",
    "    self.bert = AlbertModel.from_pretrained(\"kykim/albert-kor-base\")\n",
    "    self.drop = nn.Dropout(p=0.5)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "       return_dict=False\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  subject_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      texts = d[\"subject_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      subject_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(outputs)\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  return subject_texts, predictions, prediction_probs\n",
    "import gc\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69a7739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kykim/albert-kor-base were not used when initializing AlbertModel: ['predictions.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'sop_classifier.classifier.bias', 'predictions.dense.bias', 'predictions.decoder.bias', 'sop_classifier.classifier.weight', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_albert_kor_base = NewsSubjectClassifier(n_classes=58).to(device)\n",
    "optimizer = AdamW(model_albert_kor_base.parameters(), lr=1e-4)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "## cosine_scheduler or linear,  warmup or no warmup\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=int(total_steps*0.1),\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "from tqdm import tqdm\n",
    "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  for d in tqdm(data_loader):\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99d7b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3570 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'NewsSubjectDataset' on <module '__main__' (built-in)>\n",
      "  0%|          | 0/3570 [01:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/anmunju/Documents/PJ_repositories/boram/EDA/감정분류_감성 사전 모델 생성 시도.ipynb Cell 16'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=1'>2</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=2'>3</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=3'>4</a>\u001b[0m   train_acc, train_loss \u001b[39m=\u001b[39m train_epoch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=4'>5</a>\u001b[0m     model_albert_kor_base,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=5'>6</a>\u001b[0m     train_data_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=6'>7</a>\u001b[0m     loss_fn,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=7'>8</a>\u001b[0m     optimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=8'>9</a>\u001b[0m     device,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=9'>10</a>\u001b[0m     scheduler,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=10'>11</a>\u001b[0m     \u001b[39mlen\u001b[39;49m(train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=11'>12</a>\u001b[0m   )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=12'>13</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain loss \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m accuracy \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=14'>15</a>\u001b[0m y_review_texts, y_pred, y_pred_probs \u001b[39m=\u001b[39m get_predictions(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=15'>16</a>\u001b[0m   model_albert_kor_base,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=16'>17</a>\u001b[0m   valid_data_loader\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000015?line=17'>18</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/anmunju/Documents/PJ_repositories/boram/EDA/감정분류_감성 사전 모델 생성 시도.ipynb Cell 15'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000014?line=14'>15</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000014?line=15'>16</a>\u001b[0m correct_predictions \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000014?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m tqdm(data_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000014?line=17'>18</a>\u001b[0m   input_ids \u001b[39m=\u001b[39m d[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anmunju/Documents/PJ_repositories/boram/EDA/%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98_%EA%B0%90%EC%84%B1%20%EC%82%AC%EC%A0%84%20%EB%AA%A8%EB%8D%B8%20%EC%83%9D%EC%84%B1%20%EC%8B%9C%EB%8F%84.ipynb#ch0000014?line=18'>19</a>\u001b[0m   attention_mask \u001b[39m=\u001b[39m d[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=365'>366</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=366'>367</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=367'>368</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=311'>312</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=312'>313</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=313'>314</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=919'>920</a>\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=920'>921</a>\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=921'>922</a>\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=922'>923</a>\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=923'>924</a>\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=924'>925</a>\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=925'>926</a>\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=926'>927</a>\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=927'>928</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=928'>929</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py?line=117'>118</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py?line=118'>119</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py?line=119'>120</a>\u001b[0m _cleanup()\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py?line=122'>123</a>\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/process.py?line=123'>124</a>\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py?line=221'>222</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py?line=223'>224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py?line=280'>281</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py?line=281'>282</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py?line=282'>283</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/context.py?line=283'>284</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=30'>31</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=31'>32</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_fork.py?line=16'>17</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_fork.py?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_fork.py?line=18'>19</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=59'>60</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=60'>61</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=61'>62</a>\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=62'>63</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/multi_crawling/lib/python3.9/multiprocessing/popen_spawn_posix.py?line=63'>64</a>\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model_albert_kor_base,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(train)\n",
    "  )\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "y_review_texts, y_pred, y_pred_probs = get_predictions(\n",
    "  model_albert_kor_base,\n",
    "  valid_data_loader\n",
    ")\n",
    "answers = []\n",
    "answers.append(y_pred.tolist())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-realtor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecab3b44ec85b3fc152ce43053029da2d7fea401295eddadd715c90b258d02c3"
  },
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
