{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('novel_story_sep.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       어디 속 자이니치 분노 슬픔 탄생 대작 한국 세인 미국 작가 이민 진의 장편소설 파...\n",
       "1       어디 속 자이니치 분노 슬픔 탄생 대작 한국 세인 미국 작가 이민 진의 장편소설 파...\n",
       "2       자꾸 편의점 살 오늘 위로 편의점 밤 정체 불명 알바로 시작 웃음 감동 나비효과 망...\n",
       "3         토끼 머리 손가락 몸 안녕 내 사랑 덫 흉터 나 집 바람 모래 지배자 재회 작가 말 \n",
       "4       괴물 내 또 다른 괴물 영화 사건 매혹 문체 시선 한국 영 어덜트 소설 아몬드 타인...\n",
       "                              ...                        \n",
       "1201    기간 사랑 온 한국 대표 판타지 소설 윤 현승 작가 대표 작 늑대 최신 개정판 늑대...\n",
       "1202    불행 날 아이 운명 거부 신비 도시 버 무어 제시카 타운센드 무려 시간 동안 공 이...\n",
       "1203    아사히 신문 지난 천 년 일본 문학자 투표 위 무라카미 하루키 강상중 가장 작가 나...\n",
       "1204    인류 기원 상상 인류 미래 백만 년 가니메데 거인 인류 최초 지적 생명체 거인 종족...\n",
       "1205    경제 정책 하나 사회 파급 나비효과 시안 생각 비판 얼마나 대하 생각 소설 경제학 ...\n",
       "Name: story_sep, Length: 1206, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['story_sep']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://happy-obok.tistory.com/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA 모델에 들어갈 객체(dictionary, corpus) 만들고 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. gensim 라이브러리 설치 : 자연어를 벡터로 변환하는데 필요한 대부분의 편의 기능을 제공하고 있는 라이브러리 (Word2vec 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. gensim.models.wrappers.LdaMallet 모듈을 사용해서 LDA 모델 개수 추정\n",
    "- https://radimrehurek.com/gensim_3.8.3/models/wrappers/ldamallet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.wrappers import LdaMallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) LDA 모델에 들어갈 객체를 만든다.\n",
    "- id2word : dictionary 에 list of list of str 형식의 documents를 입력하면 Dictionary가 학습됨. 전체 말뭉치에 단어가 겹치지 않도록 하나씩 dictionary에 저장됨.\n",
    "- corpus : 단어들을 bag-of-words 형태에서 list if (token_id, token_count) 2-tuples로 변환한다.\n",
    "\n",
    "\n",
    "= [[(id2 word [id], freq) for id, freq in cp] for cp in corpus [:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = df['story_sep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word = []\n",
    "for story in stories:\n",
    "    data = list(str(story).split())\n",
    "    data_word.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.filter_extremes(no_below = 5) # 5회 이하로 등장한 단어는 삭제\n",
    "texts = data_word\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "mallet_path = '../감성사전/mallet-2.0.8/bin/mallet' \n",
    "# ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=9, id2word=id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토픽 수 별로 일관성 점수를 계산해서 가장 좋은 토픽 수의 모델 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models.coherencemodel 주제 모델에 대한 주제 일관성을 계산\n",
    "\n",
    "* model :주제가 제공되지 않은 경우 사전 훈련된 주제 모델을 제공해야 합니다. 현재 지원 LdaModel, LdaMulticore, LdaMallet와 LdaVowpalWabbit.\n",
    "* topics(list of list of str, optional) :토큰 화 된 토픽의 목록\n",
    "* texts (list of list of str, optional) :슬라이딩 창 기반 (예 : coherence =c_something) 확률 추정 기를 사용하는 일관성 모델에 필요한 토큰 화 된 텍스트.\n",
    "* corpus (iterable of list of (int, number), optional) :BoW 형식의 코퍼스.\n",
    "* dictionary (Dictionary, optional) : Gensim dictionary mapping of id word to create corpus. If model.id2 word is present, this is not needed. If both are provided, passed dictionary will be used.\n",
    "* coherence ({'u_mass', 'c_v', 'c_uci', 'c_npmi'}, optional) :\n",
    "* topn (int, optional) : 각 주제에서 추출할 최상위 단어 수에 해당하는 정수\n",
    "* processes (int, optional) : 확률 추정 단계에 사용할 프로세스 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <Coherence 점수를 계산하여 좋은 LDA 모델 찾기>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "# coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "# coherence_ldamallet #응집성 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=4, step=2):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=data_word, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mallet LDA: 7 topics, 3 topic bits, 111 topic mask\n",
      "Data loaded.\n",
      "max tokens: 1757\n",
      "total tokens: 308503\n",
      "<10> LL/token: -9.0412\n",
      "<20> LL/token: -8.61246\n",
      "<30> LL/token: -8.47564\n",
      "<40> LL/token: -8.40695\n",
      "\n",
      "0\t7.14286\t시대 우리 한국 문학 역사 위 사회 장 책 가장 세기 이자 전쟁 간 대표 은 자유 태백산맥 통해 제 \n",
      "1\t7.14286\t아이 청소년 친구 엄마 위해 우리 더 주인공 제 학교 너 가족 일 세 시작 날 아버지 몸 대한 자기 \n",
      "2\t7.14286\t소녀 권 책 세상 일 온 시작 속 드라마 왕 사랑 마음 다시 은 알 를 살 내 향 김 \n",
      "3\t7.14286\t알 그녀 사랑 이름 를 생각 독자 내 나 누군가 저 남편 시간 과정 왜 모든 눈 위 발견 네 \n",
      "4\t7.14286\t독자 등 책 사건 의 간 전 은 통해 가장 문학 미스터리 작 시리즈 선정 베스트셀러 일본 부 상 세계 \n",
      "5\t7.14286\t인간 의 여성 세계 독자 위해 대한 사회 주인공 등장 화 현실 속 인류 중 등 사실 무엇 삶 상황 \n",
      "6\t7.14286\t사랑 삶 우리 나 마음 때 생각 집 순간 죽음 시간 두 속 일 서로 그녀 소년 세계 아내 은 \n",
      "\n",
      "<50> LL/token: -8.37006\n",
      "<60> LL/token: -8.34932\n",
      "<70> LL/token: -8.3339\n",
      "<80> LL/token: -8.3208\n",
      "<90> LL/token: -8.31374\n",
      "\n",
      "0\t7.14286\t우리 문학 시대 역사 한국 위 장 사회 책 가장 세기 이자 은 간 전쟁 대표 자유 등 태백산맥 다시 \n",
      "1\t7.14286\t아이 청소년 엄마 친구 가족 우리 너 학교 위해 더 날 주인공 인물 아버지 세 일 제 시작 대한 삶 \n",
      "2\t7.14286\t소녀 권 책 온 속 세상 일 시작 드라마 사랑 마음 왕 를 다시 은 살 알 그녀 위해 내 \n",
      "3\t7.14286\t알 나 생각 이름 그녀 내 시간 사랑 모든 누군가 두 과정 독자 곳 남편 저 왜 위 를 눈 \n",
      "4\t7.14286\t독자 책 사건 등 간 전 의 통해 미스터리 베스트셀러 시리즈 세계 중 은 최고 작 일본 상 남자 영화 \n",
      "5\t7.14286\t인간 의 여성 위해 사회 대한 세계 등장 화 속 현실 인류 주인공 존재 시작 사실 때문 무엇 소세키 통해 \n",
      "6\t7.14286\t사랑 삶 우리 나 마음 집 때 순간 일 생각 죽음 속 서로 시간 그녀 두 소년 살 아내 은 \n",
      "\n",
      "<100> LL/token: -8.30711\n",
      "<110> LL/token: -8.3026\n",
      "<120> LL/token: -8.30254\n",
      "<130> LL/token: -8.29907\n",
      "<140> LL/token: -8.29703\n",
      "\n",
      "0\t7.14286\t우리 문학 시대 역사 한국 위 책 장 간 사회 가장 세기 전쟁 은 등 대표 이자 자유 태백산맥 권 \n",
      "1\t7.14286\t아이 청소년 엄마 가족 우리 친구 학교 위해 아버지 주인공 더 시작 너 세 대한 제 일 또 몸 누구 \n",
      "2\t7.14286\t소녀 권 책 온 시작 일 속 세상 위해 왕 사랑 은 살 마음 를 위 다시 향 그녀 알 \n",
      "3\t7.14286\t나 알 이름 그녀 생각 시간 두 내 누군가 눈 독자 저 사랑 왜 위 다른 세계 발견 속 남편 \n",
      "4\t7.14286\t독자 사건 책 등 간 전 의 세계 미스터리 시리즈 베스트셀러 최고 중 은 통해 작 가장 미국 비밀 상 \n",
      "5\t7.14286\t인간 의 사회 여성 대한 위해 세계 주인공 통해 현실 독자 등장 인류 속 존재 무엇 김 때문 화 사실 \n",
      "6\t7.14286\t사랑 삶 우리 마음 나 집 때 죽음 일 순간 생각 두 시간 서로 그녀 소년 속 살 아내 그것 \n",
      "\n",
      "<150> LL/token: -8.29458\n",
      "<160> LL/token: -8.29094\n",
      "<170> LL/token: -8.29208\n",
      "<180> LL/token: -8.28935\n",
      "<190> LL/token: -8.28631\n",
      "\n",
      "0\t7.14286\t시대 문학 우리 역사 한국 위 책 장 은 간 세기 가장 전쟁 사회 등 대표 이자 자유 권 태백산맥 \n",
      "1\t7.14286\t아이 청소년 엄마 우리 친구 위해 가족 학교 더 너 주인공 누구 아버지 지금 마음 제 날 모습 내 살 \n",
      "2\t7.14286\t소녀 권 책 온 세상 시작 속 일 은 사랑 왕 위해 그녀 알 다시 위 향 드라마 마음 살 \n",
      "3\t7.14286\t나 알 이름 생각 시간 내 다시 왜 누군가 저 곳 그녀 모든 속 발견 를 세계 독자 사랑 눈 \n",
      "4\t7.14286\t독자 사건 책 등 전 간 의 세계 미스터리 베스트셀러 시리즈 최고 통해 중 비밀 남자 영화 가장 대한 미국 \n",
      "5\t7.14286\t인간 의 사회 여성 대한 위해 현실 세계 무엇 인류 주인공 통해 독자 때문 김 존재 등장 소세키 사실 반전 \n",
      "6\t7.14286\t사랑 삶 우리 마음 나 집 일 때 순간 생각 그녀 죽음 서로 속 두 시간 남자 살 아내 다른 \n",
      "\n",
      "<200> LL/token: -8.28416\n",
      "<210> LL/token: -8.28305\n",
      "<220> LL/token: -8.28429\n",
      "<230> LL/token: -8.2796\n",
      "<240> LL/token: -8.28053\n",
      "\n",
      "0\t7.14286\t문학 시대 우리 역사 한국 위 책 장 간 은 사회 세기 전쟁 등 가장 대표 이자 자유 독자 통해 \n",
      "1\t7.14286\t아이 엄마 청소년 친구 가족 우리 위해 학교 너 더 누구 제 날 고민 아버지 대한 나 주인공 또 마음 \n",
      "2\t7.14286\t소녀 권 책 온 사랑 세상 시작 속 일 왕 마음 은 그녀 다시 위해 알 드라마 살 향 주인공 \n",
      "3\t7.14286\t나 생각 시간 알 내 이름 우리 왜 눈 때 누군가 곳 과정 를 모든 다른 위 속 독자 기억 \n",
      "4\t7.14286\t독자 사건 책 등 간 전 의 세계 통해 미스터리 베스트셀러 남자 시리즈 비밀 중 최고 영화 작 가장 상 \n",
      "5\t7.14286\t인간 의 사회 여성 위해 대한 세계 등장 김 존재 속 인류 무엇 현실 사실 등 때문 주인공 저자 반전 \n",
      "6\t7.14286\t사랑 삶 우리 나 마음 집 일 그녀 때 순간 죽음 두 서로 생각 살 속 소년 아내 시간 남자 \n",
      "\n",
      "<250> LL/token: -8.27505\n",
      "<260> LL/token: -8.27745\n",
      "<270> LL/token: -8.27744\n",
      "<280> LL/token: -8.27504\n",
      "<290> LL/token: -8.27716\n",
      "\n",
      "0\t7.14286\t문학 역사 우리 시대 한국 위 책 은 장 간 가장 이자 세기 등 전쟁 사회 대표 자유 독자 태백산맥 \n",
      "1\t7.14286\t아이 엄마 청소년 우리 친구 마음 위해 학교 너 아버지 가족 내 누구 제 더 주인공 아빠 고민 또 지금 \n",
      "2\t7.14286\t소녀 권 책 온 시작 세상 사랑 속 그녀 왕 알 살 일 은 향 위해 마음 드라마 다시 를 \n",
      "3\t7.14286\t나 시간 생각 알 이름 내 때 왜 곳 모든 다른 누군가 눈 문장 속 세계 발견 기억 과정 다시 \n",
      "4\t7.14286\t독자 사건 책 등 간 전 의 세계 미스터리 남자 베스트셀러 영화 시리즈 최고 통해 가장 중 작 상 대한 \n",
      "5\t7.14286\t인간 의 사회 위해 여성 대한 세계 김 통해 독자 현실 무엇 등장 속 인류 등 때문 존재 주인공 삶 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 나 집 일 때 마음 순간 죽음 서로 생각 두 속 살 소년 아내 뒤 다른 \n",
      "\n",
      "<300> LL/token: -8.27413\n",
      "<310> LL/token: -8.27494\n",
      "<320> LL/token: -8.27659\n",
      "<330> LL/token: -8.27645\n",
      "<340> LL/token: -8.27598\n",
      "\n",
      "0\t7.14286\t문학 역사 우리 시대 한국 위 책 간 장 가장 등 세기 은 전쟁 이자 대표 사회 자유 일본 독자 \n",
      "1\t7.14286\t아이 엄마 청소년 우리 친구 마음 가족 위해 아버지 학교 너 집 누구 날 주인공 나 고민 더 생각 제 \n",
      "2\t7.14286\t권 책 소녀 온 속 세상 사랑 왕 위해 시작 일 마음 를 중 드라마 향 알 은 그녀 다시 \n",
      "3\t7.14286\t나 시간 알 내 생각 이름 때 다른 눈 곳 를 우리 누군가 지금 위 모든 기억 왜 저 과정 \n",
      "4\t7.14286\t독자 사건 책 등 전 간 미스터리 베스트셀러 비밀 시리즈 세계 의 은 남자 영화 통해 미국 최고 상 대한 \n",
      "5\t7.14286\t인간 사회 의 여성 대한 위해 세계 통해 현실 김 독자 등장 무엇 때문 인류 존재 등 주인공 사실 속 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 일 마음 때 나 순간 집 살 두 죽음 생각 서로 속 소년 아내 뒤 감정 \n",
      "\n",
      "<350> LL/token: -8.27688\n",
      "<360> LL/token: -8.27537\n",
      "<370> LL/token: -8.27381\n",
      "<380> LL/token: -8.27615\n",
      "<390> LL/token: -8.27404\n",
      "\n",
      "0\t7.14286\t문학 역사 우리 시대 한국 책 위 간 은 장 가장 세기 사회 전쟁 등 대표 이자 자유 권 독자 \n",
      "1\t7.14286\t아이 엄마 청소년 우리 친구 가족 학교 아버지 대한 너 마음 더 집 위해 날 살 주인공 아빠 고민 일 \n",
      "2\t7.14286\t권 책 온 시작 세상 속 그녀 왕 은 위해 소녀 사랑 일 알 위 드라마 향 마음 다시 살 \n",
      "3\t7.14286\t나 시간 생각 알 때 이름 내 곳 다른 눈 를 왜 누군가 모든 우리 저 세계 지금 위 다시 \n",
      "4\t7.14286\t독자 사건 책 등 전 세계 의 간 미스터리 베스트셀러 시리즈 비밀 남자 영화 중 은 최고 두 미국 상 \n",
      "5\t7.14286\t인간 사회 여성 의 대한 위해 등 김 세계 주인공 현실 독자 존재 통해 인류 때문 한국 무엇 등장 속 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 나 마음 일 순간 때 집 죽음 서로 두 소년 생각 소녀 속 살 아내 감정 \n",
      "\n",
      "<400> LL/token: -8.27465\n",
      "<410> LL/token: -8.27388\n",
      "<420> LL/token: -8.27559\n",
      "<430> LL/token: -8.27415\n",
      "<440> LL/token: -8.27663\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 우리 한국 책 위 간 장 은 등 세기 가장 전쟁 이자 대표 권 의 사회 일본 \n",
      "1\t7.14286\t아이 엄마 청소년 우리 친구 가족 학교 마음 위해 너 아버지 집 일 더 대한 내 주인공 인물 제 나 \n",
      "2\t7.14286\t권 책 온 속 은 시작 일 사랑 왕 알 세상 마음 향 드라마 독자 소녀 꽃 위해 다시 주인공 \n",
      "3\t7.14286\t나 시간 생각 알 때 이름 내 다른 곳 왜 누군가 저 모든 눈 날 위 우리 를 과정 발견 \n",
      "4\t7.14286\t독자 사건 책 등 전 간 세계 미스터리 베스트셀러 남자 시리즈 비밀 두 영화 최고 의 미국 상 통해 스릴러 \n",
      "5\t7.14286\t인간 사회 대한 여성 의 위해 현실 김 등 통해 때문 한국 인류 세계 주인공 등장 독자 사실 속 무엇 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 일 마음 집 때 순간 나 죽음 두 서로 살 소녀 속 소년 생각 아내 뒤 \n",
      "\n",
      "<450> LL/token: -8.27577\n",
      "<460> LL/token: -8.27366\n",
      "<470> LL/token: -8.27375\n",
      "<480> LL/token: -8.27604\n",
      "<490> LL/token: -8.27698\n",
      "\n",
      "0\t7.14286\t문학 역사 우리 시대 한국 위 간 책 장 은 가장 등 이자 세기 전쟁 독자 사회 대표 통해 일본 \n",
      "1\t7.14286\t아이 엄마 청소년 우리 가족 친구 마음 학교 집 위해 너 살 아버지 내 주인공 고민 지금 누구 제 일 \n",
      "2\t7.14286\t권 책 온 시작 속 세상 왕 향 를 다시 사랑 은 독자 소녀 꽃 위 일 위해 주인공 알 \n",
      "3\t7.14286\t나 시간 생각 알 이름 눈 내 다른 저 곳 날 를 우리 때 모든 누군가 왜 일 과정 더 \n",
      "4\t7.14286\t독자 사건 책 등 전 세계 간 미스터리 베스트셀러 영화 최고 두 비밀 남자 미국 상 중 시리즈 작 의 \n",
      "5\t7.14286\t인간 사회 의 대한 여성 위해 통해 현실 김 세계 한국 존재 때문 주인공 인류 등장 무엇 독자 당시 등 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 일 때 마음 순간 죽음 집 두 나 서로 소녀 살 소년 속 생각 아내 의 \n",
      "\n",
      "<500> LL/token: -8.27706\n",
      "<510> LL/token: -8.27333\n",
      "<520> LL/token: -8.27443\n",
      "<530> LL/token: -8.27251\n",
      "<540> LL/token: -8.27152\n",
      "\n",
      "0\t7.14286\t문학 역사 우리 한국 시대 위 책 간 장 은 등 가장 전쟁 세기 이자 독자 대표 권 일본 사회 \n",
      "1\t7.14286\t아이 엄마 청소년 우리 친구 가족 학교 위해 집 너 살 마음 주인공 고민 대한 아버지 아빠 더 인물 삶 \n",
      "2\t7.14286\t권 책 온 시작 독자 속 왕 세상 그녀 일 사랑 마음 를 위 소녀 꽃 알 살 위해 드라마 \n",
      "3\t7.14286\t나 시간 생각 내 이름 알 때 다시 저 눈 다른 속 모든 날 왜 우리 누군가 기억 곳 문장 \n",
      "4\t7.14286\t독자 사건 책 전 등 간 세계 미스터리 베스트셀러 영화 의 두 남자 최고 시리즈 미국 비밀 중 상 매력 \n",
      "5\t7.14286\t인간 사회 의 대한 여성 위해 통해 김 현실 등 인류 때문 주인공 자유 세계 등장 속 당시 삶 무엇 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 일 마음 때 순간 죽음 서로 나 두 집 소녀 소년 생각 아내 속 감정 여자 \n",
      "\n",
      "<550> LL/token: -8.27258\n",
      "<560> LL/token: -8.2749\n",
      "<570> LL/token: -8.27226\n",
      "<580> LL/token: -8.27401\n",
      "<590> LL/token: -8.27481\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 한국 우리 책 간 위 은 장 등 세기 가장 전쟁 이자 독자 권 일본 삶 사회 \n",
      "1\t7.14286\t아이 엄마 청소년 친구 우리 가족 집 학교 나 아버지 주인공 마음 살 위해 인물 고민 아빠 제 일 더 \n",
      "2\t7.14286\t권 책 온 속 시작 독자 세상 왕 소녀 향 를 사랑 은 일 알 드라마 위 꽃 살 마음 \n",
      "3\t7.14286\t나 시간 때 내 생각 알 이름 눈 곳 날 저 다른 우리 왜 일 누군가 다시 화 위 안 \n",
      "4\t7.14286\t독자 사건 책 전 등 세계 간 미스터리 영화 베스트셀러 중 남자 의 비밀 최고 두 미국 상 대한 시리즈 \n",
      "5\t7.14286\t인간 사회 대한 여성 의 위해 김 현실 등 세계 등장 무엇 인류 통해 자유 의미 한국 속 때문 주인공 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 마음 일 순간 때 집 두 서로 나 죽음 속 세상 소녀 소년 아내 살 의 \n",
      "\n",
      "<600> LL/token: -8.27073\n",
      "<610> LL/token: -8.27269\n",
      "<620> LL/token: -8.27192\n",
      "<630> LL/token: -8.27012\n",
      "<640> LL/token: -8.27293\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 한국 우리 위 간 책 등 장 가장 은 세기 이자 독자 전쟁 삶 의 대표 세 \n",
      "1\t7.14286\t아이 엄마 청소년 가족 친구 우리 학교 더 위해 집 인물 아버지 마음 주인공 살 고민 대한 아빠 아들 나 \n",
      "2\t7.14286\t권 책 온 속 독자 시작 왕 를 위 은 사랑 드라마 살 운명 일 그녀 꽃 세상 소녀 주인공 \n",
      "3\t7.14286\t나 시간 때 생각 내 이름 눈 알 날 일 곳 저 다른 모든 안 를 기억 누군가 그것 우리 \n",
      "4\t7.14286\t독자 사건 책 전 등 간 세계 미스터리 남자 두 영화 베스트셀러 최고 인생 미국 은 상 비밀 매력 시리즈 \n",
      "5\t7.14286\t인간 사회 의 대한 위해 여성 현실 등 통해 김 생각 때문 인류 의미 등장 자유 독자 세계 경험 속 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 마음 일 순간 집 때 서로 두 속 소녀 죽음 나 세상 아내 살 의 소년 \n",
      "\n",
      "<650> LL/token: -8.27513\n",
      "<660> LL/token: -8.27541\n",
      "<670> LL/token: -8.27342\n",
      "<680> LL/token: -8.27219\n",
      "<690> LL/token: -8.27458\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 우리 한국 위 간 책 은 장 가장 세기 등 이자 전쟁 일본 사회 독자 대표 삶 \n",
      "1\t7.14286\t아이 엄마 청소년 가족 친구 우리 집 학교 위해 아버지 마음 살 인물 제 고민 아빠 대한 앞 더 나 \n",
      "2\t7.14286\t권 독자 책 온 속 왕 드라마 시작 중 를 은 사랑 세상 위 위해 향 꽃 소녀 마음 일 \n",
      "3\t7.14286\t나 시간 내 생각 때 이름 눈 알 일 다른 곳 날 저 누군가 왜 위 모든 를 다시 몸 \n",
      "4\t7.14286\t독자 사건 책 등 전 세계 미스터리 간 베스트셀러 최고 영화 남자 시리즈 미국 인생 상 매력 대한 두 스릴러 \n",
      "5\t7.14286\t인간 사회 대한 여성 의 세계 통해 의미 위해 현실 김 등 주인공 인류 등장 자유 때문 무엇 세상 속 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 마음 때 일 죽음 순간 서로 의 두 소녀 속 집 나 세상 아내 소년 생각 \n",
      "\n",
      "<700> LL/token: -8.27547\n",
      "<710> LL/token: -8.27305\n",
      "<720> LL/token: -8.27452\n",
      "<730> LL/token: -8.27043\n",
      "<740> LL/token: -8.27284\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 우리 한국 책 위 간 가장 세기 장 은 등 전쟁 이자 독자 일본 사회 의 삶 \n",
      "1\t7.14286\t아이 엄마 청소년 가족 친구 우리 학교 집 아버지 마음 위해 제 주인공 인물 더 나 고민 살 또 내 \n",
      "2\t7.14286\t권 책 온 독자 속 시작 세상 왕 를 소녀 은 드라마 살 사랑 위 일 마음 위해 향 로맨스 \n",
      "3\t7.14286\t나 시간 때 내 생각 알 눈 이름 다른 일 저 날 우리 곳 몸 화 누군가 문장 를 모든 \n",
      "4\t7.14286\t독자 사건 책 전 등 간 세계 미스터리 영화 베스트셀러 대한 남자 최고 중 시리즈 마지막 미국 너 상 두 \n",
      "5\t7.14286\t인간 사회 대한 의 위해 여성 통해 세계 현실 등 김 의미 생각 인류 자유 등장 때문 무엇 독자 존재 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 마음 일 순간 서로 집 죽음 두 때 소녀 속 나 소년 아내 살 감정 여자 \n",
      "\n",
      "<750> LL/token: -8.27435\n",
      "<760> LL/token: -8.27482\n",
      "<770> LL/token: -8.27524\n",
      "<780> LL/token: -8.27395\n",
      "<790> LL/token: -8.27428\n",
      "\n",
      "0\t7.14286\t문학 역사 우리 시대 한국 위 책 간 은 장 등 가장 세기 전쟁 독자 일본 이자 사회 삶 태백산맥 \n",
      "1\t7.14286\t아이 엄마 청소년 가족 친구 우리 집 학교 마음 살 제 아버지 위해 아빠 주인공 더 고민 지금 인물 언니 \n",
      "2\t7.14286\t권 온 책 시작 독자 속 왕 를 세상 드라마 사랑 일 그녀 소녀 위 은 중 알 마음 등 \n",
      "3\t7.14286\t나 시간 내 때 생각 이름 눈 알 다른 날 일 저 를 곳 왜 화 기억 누군가 다시 더 \n",
      "4\t7.14286\t독자 사건 책 전 등 간 세계 미스터리 시리즈 베스트셀러 최고 남자 영화 미국 비밀 대한 인생 너 상 통해 \n",
      "5\t7.14286\t인간 사회 의 대한 위해 여성 세계 때문 현실 통해 의미 김 생각 인류 속 주인공 자유 무엇 등 한국 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 일 마음 순간 두 때 죽음 집 서로 소녀 의 속 남자 아내 나 살 여자 \n",
      "\n",
      "<800> LL/token: -8.27643\n",
      "<810> LL/token: -8.27587\n",
      "<820> LL/token: -8.27626\n",
      "<830> LL/token: -8.27658\n",
      "<840> LL/token: -8.27787\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 우리 한국 책 간 위 은 가장 등 장 세기 전쟁 이자 독자 삶 대표 사회 일본 \n",
      "1\t7.14286\t아이 엄마 청소년 친구 가족 학교 우리 마음 위해 집 아버지 제 나 고민 아빠 주인공 속 살 더 첫 \n",
      "2\t7.14286\t권 책 온 시작 속 독자 왕 그녀 소녀 은 드라마 세상 위 를 중 등 일 알 사랑 로맨스 \n",
      "3\t7.14286\t나 시간 내 때 생각 날 일 이름 눈 다른 안 모든 곳 알 저 우리 누군가 를 다시 화 \n",
      "4\t7.14286\t사건 독자 책 전 등 세계 간 미스터리 베스트셀러 의 최고 비밀 상 시리즈 미국 대한 중 너 영화 남자 \n",
      "5\t7.14286\t인간 사회 의 대한 위해 통해 여성 독자 현실 세계 김 의미 인류 등 등장 주인공 자유 때문 무엇 우리 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 일 마음 죽음 순간 때 집 두 서로 소녀 살 남자 아내 속 모습 세상 생각 \n",
      "\n",
      "<850> LL/token: -8.27775\n",
      "<860> LL/token: -8.27576\n",
      "<870> LL/token: -8.27971\n",
      "<880> LL/token: -8.27793\n",
      "<890> LL/token: -8.27803\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 우리 한국 위 간 책 장 독자 은 세기 등 가장 이자 전쟁 삶 일본 대표 사회 \n",
      "1\t7.14286\t아이 엄마 청소년 친구 우리 가족 집 학교 위해 마음 제 인물 더 나 살 아버지 고민 세 대한 아빠 \n",
      "2\t7.14286\t권 독자 책 온 왕 속 시작 를 은 위 세상 드라마 등 일 중 알 소녀 로맨스 살 주인공 \n",
      "3\t7.14286\t나 시간 내 때 생각 눈 일 이름 알 날 다른 곳 기억 저 모든 안 우리 왜 화 누군가 \n",
      "4\t7.14286\t독자 사건 책 전 등 세계 미스터리 간 남자 베스트셀러 인생 최고 너 영화 미국 두 상 시리즈 대한 중 \n",
      "5\t7.14286\t인간 사회 대한 의 위해 세계 여성 통해 현실 김 등 때문 인류 속 무엇 생각 한국 등장 자유 주인공 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 마음 순간 일 죽음 때 두 소녀 집 서로 속 아내 살 소년 나 감정 여자 \n",
      "\n",
      "<900> LL/token: -8.2802\n",
      "<910> LL/token: -8.28067\n",
      "<920> LL/token: -8.27769\n",
      "<930> LL/token: -8.27557\n",
      "<940> LL/token: -8.2763\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 우리 한국 위 간 책 은 등 장 세기 독자 이자 가장 전쟁 일본 대표 삶 의 \n",
      "1\t7.14286\t아이 엄마 청소년 우리 가족 친구 학교 집 인물 위해 아버지 주인공 살 고민 마음 아빠 상처 제 대한 더 \n",
      "2\t7.14286\t권 책 독자 온 속 시작 왕 를 위 드라마 일 중 은 세상 소녀 알 살 마음 로맨스 등 \n",
      "3\t7.14286\t나 시간 내 생각 눈 때 날 알 이름 다른 일 곳 모든 저 우리 몸 왜 기억 안 를 \n",
      "4\t7.14286\t사건 독자 책 전 등 세계 간 미스터리 베스트셀러 영화 시리즈 최고 남자 너 미국 대한 상 가장 중 비밀 \n",
      "5\t7.14286\t인간 사회 대한 의 세계 통해 여성 위해 한국 의미 현실 생각 등장 책 김 인류 등 자유 독자 속 \n",
      "6\t7.14286\t사랑 삶 우리 그녀 마음 일 순간 죽음 두 서로 집 소녀 때 속 나 아내 감정 모습 남자 살 \n",
      "\n",
      "<950> LL/token: -8.27821\n",
      "<960> LL/token: -8.27815\n",
      "<970> LL/token: -8.27966\n",
      "<980> LL/token: -8.27799\n",
      "<990> LL/token: -8.27899\n",
      "\n",
      "0\t7.14286\t문학 역사 시대 우리 한국 간 책 위 등 은 가장 장 세기 전쟁 이자 독자 일본 사회 태백산맥 다시 \n",
      "1\t7.14286\t아이 엄마 청소년 친구 가족 학교 우리 집 마음 나 위해 살 인물 아버지 세 고민 제 아빠 주인공 일 \n",
      "2\t7.14286\t권 책 온 독자 속 시작 왕 소녀 드라마 를 위 위해 중 세상 은 일 살 로맨스 그녀 지금 \n",
      "3\t7.14286\t나 시간 내 때 생각 눈 이름 날 곳 알 다른 우리 일 다시 저 모든 몸 안 화 왜 \n",
      "4\t7.14286\t사건 독자 책 전 등 세계 간 미스터리 남자 베스트셀러 인생 두 미국 시리즈 상 비밀 최고 영화 너 대한 \n",
      "5\t7.14286\t인간 대한 의 사회 세계 통해 여성 위해 의미 독자 무엇 김 현실 때문 생각 등장 우리 인류 한국 등 \n",
      "6\t7.14286\t사랑 삶 그녀 우리 마음 일 순간 집 때 죽음 두 서로 모습 소녀 생각 속 감정 아내 남자 의 \n",
      "\n",
      "<1000> LL/token: -8.27706\n",
      "\n",
      "Total time: 36 seconds\n",
      "Mallet LDA: 8 topics, 3 topic bits, 111 topic mask\n",
      "Data loaded.\n",
      "max tokens: 1757\n",
      "total tokens: 308503\n",
      "<10> LL/token: -9.1071\n",
      "<20> LL/token: -8.63159\n",
      "<30> LL/token: -8.47554\n",
      "<40> LL/token: -8.40944\n",
      "\n",
      "0\t6.25\t독자 권 시작 책 온 너 왕 세상 사랑 드라마 주인공 감동 중 은 위해 베스트셀러 듯 마음 내 향 \n",
      "1\t6.25\t책 나 세계 우리 독자 를 시간 속 길 인물 이름 사랑 삶 생각 선택 의미 한국 현실 알 위 \n",
      "2\t6.25\t나 마음 아이 엄마 내 청소년 우리 친구 소녀 시간 가족 생각 거 집 그녀 날 살 때 소년 다른 \n",
      "3\t6.25\t한국 문학 역사 간 우리 사회 시대 책 위 일본 가장 독자 등 의 장 세 세기 태백산맥 대표 여성 \n",
      "4\t6.25\t사건 독자 등 중 문학 속 대한 개 여성 사실 생각 현실 통해 책 두 화 자유 지금 세상 저자 \n",
      "5\t6.25\t사랑 일 그녀 시작 집 안 모습 아내 기억 때 남편 못 몸 알 왜 우리 관계 생활 때문 인간 \n",
      "6\t6.25\t인간 시리즈 의 주인공 세계 전 영화 인류 알 아이 제 간 위해 문제 장르 등 대한 지구 재미 통해 \n",
      "7\t6.25\t삶 사랑 죽음 우리 세계 속 두 은 인생 순간 때 남자 어머니 무엇 고통 인물 전 이자 대한 의 \n",
      "\n",
      "<50> LL/token: -8.37229\n",
      "<60> LL/token: -8.34617\n",
      "<70> LL/token: -8.33355\n",
      "<80> LL/token: -8.32024\n",
      "<90> LL/token: -8.31633\n"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run.\n",
    "limit=11; start=7; step=1;\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=start, limit=limit, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(start, limit, step)\n",
    "topic_num = 0\n",
    "count = 0\n",
    "max_coherence = 0\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", cv)\n",
    "    coherence = cv\n",
    "    if coherence >= max_coherence:\n",
    "        max_coherence = coherence\n",
    "        topic_num = m\n",
    "        model_list_num = count   \n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[model_list_num]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "print(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    #ldamodel[corpus]: lda_model에 corpus를 넣어 각 토픽 당 확률을 알 수 있음\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num,topn=10)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    print(type(sent_topics_df))\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    # sent_topics_df = pd.concat([sent_topics_df, Data['text'],Data['timestamp'],Data['tweet_url'],Data['screen_name'],Data['label']], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format\n",
    "df_topic_tweet = df_topic_sents_keywords.reset_index()\n",
    "df_topic_tweet.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text','Timestamp', 'Tweet_url','Screen_name','label']\n",
    "\n",
    "# Show각 문서에 대한 토픽\n",
    "#df_dominant_topic=df_dominant_topic.sort_values(by=['Dominant_Topic'])\n",
    "#df_topic_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "topic_counts.sort_index(inplace=True)\n",
    "\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "topic_contribution\n",
    "\n",
    "lda_inform = pd.concat([sent_topics_sorteddf_mallet, topic_counts, topic_contribution], axis=1)\n",
    "lda_inform.columns=[\"Topic_Num\", \"Topic_Perc_Contrib\", \"Keywords\", \"Text\", \"timestamp\", \"tweet_url\",\"screen_name\",\"label\",\"Num_Documents\", \"Perc_Documents\"]\n",
    "lda_inform = lda_inform[[\"Topic_Num\",\"Keywords\",\"Num_Documents\",\"Perc_Documents\"]]\n",
    "lda_inform\n",
    "#lda_inform.Topic_Num = lda_inform.Topic_Num.astype(int)\n",
    "lda_inform['Topic_Num'] =lda_inform['Topic_Num'] +1\n",
    "lda_inform.Topic_Num = lda_inform.Topic_Num.astype(str)\n",
    "lda_inform['Topic_Num'] =lda_inform['Topic_Num'].str.split('.').str[0]\n",
    "df_topic_tweet['Dominant_Topic'] =df_topic_tweet['Dominant_Topic'] +1\n",
    "df_topic_tweet.Dominant_Topic = df_topic_tweet.Dominant_Topic.astype(str)\n",
    "df_topic_tweet['Dominant_Topic'] =df_topic_tweet['Dominant_Topic'].str.split('.').str[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08b123dd7174979f42e8d8d99436980ff337f7b8b34ef63d166a44720f231f79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('mulcam_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
